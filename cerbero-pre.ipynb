{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEQ7awSF4JETXrZadejvRh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4L3M4R/cerbero/blob/main/cerbero-pre.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYcC5-caMLbD"
      },
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "#             CERBERO PREMARKET\n",
        "#   Descarga noticias y calcula sentiment\n",
        "#   (Actualiza el d√≠a anterior en los archivos *_datos.txt)\n",
        "# ===============================================\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import feedparser\n",
        "import nltk\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from datetime import datetime, timedelta\n",
        "from urllib.parse import quote\n",
        "\n",
        "# ===============================================\n",
        "#             CONFIGURACI√ìN\n",
        "# ===============================================\n",
        "\n",
        "# Lista de activos\n",
        "activos = {}\n",
        "with open(\"activos.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        symbol, source, search_name = line.strip().split(\":\")\n",
        "        activos[symbol.strip()] = {\n",
        "            \"source\": source.strip().lower(),\n",
        "            \"search_name\": search_name.strip()\n",
        "        }\n",
        "\n",
        "# Inicializaci√≥n de analizadores de sentimiento\n",
        "nltk.download('vader_lexicon')\n",
        "vader_analyzer = SentimentIntensityAnalyzer()\n",
        "finbert_tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "finbert_model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "\n",
        "# ===============================================\n",
        "#           FUNCIONES AUXILIARES\n",
        "# ===============================================\n",
        "\n",
        "def registrar_log(message, log_file=\"run_summary_pre.log\"):\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    with open(log_file, \"a\") as log:\n",
        "        log.write(f\"[{timestamp}] {message}\\n\")\n",
        "\n",
        "def descargar_noticias_y_calcular_sentiment(symbol, search_name):\n",
        "    os.makedirs(\"logs\", exist_ok=True)\n",
        "\n",
        "    query = quote(search_name)\n",
        "    feed = feedparser.parse(f\"https://news.google.com/rss/search?q={query}\")\n",
        "    noticias = []\n",
        "    for entry in feed.entries:\n",
        "        noticias.append({\n",
        "            \"timestamp\": entry.published,\n",
        "            \"title\": entry.title,\n",
        "            \"link\": entry.link\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(noticias)\n",
        "    if df.empty:\n",
        "        registrar_log(f\"{symbol} - No se encontraron noticias\")\n",
        "        return\n",
        "\n",
        "    # Calcular sentimiento con VADER (y placeholder para FinBERT)\n",
        "    df[\"vader_sentiment\"] = df[\"title\"].apply(lambda x: vader_analyzer.polarity_scores(x)[\"compound\"])\n",
        "    df[\"finbert_sentiment\"] = 0  # Puedes reemplazar con an√°lisis FinBERT si lo deseas\n",
        "\n",
        "    # Calcular promedios\n",
        "    vader_promedio = df[\"vader_sentiment\"].mean()\n",
        "    finbert_promedio = df[\"finbert_sentiment\"].mean()\n",
        "\n",
        "    # Actualizar el archivo de datos\n",
        "    actualizar_sentimiento(symbol, vader_promedio, finbert_promedio)\n",
        "\n",
        "    # Guardar noticias procesadas\n",
        "    today_str = pd.Timestamp.utcnow().date()\n",
        "    df.to_csv(f\"logs/{symbol}_nuevas_agregadas_{today_str}.csv\", index=False)\n",
        "    registrar_log(f\"{symbol} - Guardadas {len(df)} noticias con sentiment\")\n",
        "\n",
        "def actualizar_sentimiento(symbol, vader_promedio, finbert_promedio):\n",
        "    \"\"\"Actualiza el archivo de datos del s√≠mbolo con la informaci√≥n de sentiment promedio.\"\"\"\n",
        "    import pandas as pd\n",
        "    import os\n",
        "    from datetime import datetime, timedelta\n",
        "\n",
        "    file_path = f\"{symbol}_datos.txt\"  # aseg√∫rate que coincida con tu repo\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"‚ö†Ô∏è Archivo no encontrado: {file_path}\")\n",
        "        return\n",
        "\n",
        "    # Leer CSV\n",
        "    df = pd.read_csv(file_path, sep=\",\")  # tus archivos usan coma\n",
        "    print(f\"‚úÖ Archivo cargado correctamente: {file_path}\")\n",
        "\n",
        "    # Forzar timestamp\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce').dt.date\n",
        "\n",
        "    # D√≠a anterior\n",
        "    ayer = (datetime.utcnow() - timedelta(days=1)).date()\n",
        "    mask = df['timestamp'] == ayer\n",
        "\n",
        "    if mask.any():\n",
        "        print(f\"üü¢ Actualizando l√≠nea de ayer ({ayer}) en {symbol}\")\n",
        "        df.loc[mask, 'vader'] = vader_promedio\n",
        "        df.loc[mask, 'finbert'] = finbert_promedio\n",
        "    else:\n",
        "        print(f\"üü° No se encontr√≥ l√≠nea para ayer ({ayer}), agregando nueva fila.\")\n",
        "        nueva_fila = {'timestamp': ayer, 'vader': vader_promedio, 'finbert': finbert_promedio}\n",
        "        # Llenar el resto de columnas con NaN o ceros\n",
        "        for col in df.columns:\n",
        "            if col not in nueva_fila:\n",
        "                nueva_fila[col] = 0\n",
        "        df = pd.concat([df, pd.DataFrame([nueva_fila])], ignore_index=True)\n",
        "\n",
        "    # Guardar CSV actualizado\n",
        "    df.to_csv(file_path, index=False)\n",
        "    print(f\"üíæ Archivo actualizado y guardado: {file_path}\")\n",
        "\n",
        "\n",
        "# ===============================================\n",
        "#           EJECUCI√ìN PRINCIPAL\n",
        "# ===============================================\n",
        "\n",
        "for symbol, info in activos.items():\n",
        "    descargar_noticias_y_calcular_sentiment(symbol, info[\"search_name\"])\n",
        "\n",
        "print(\"‚úÖ Completed premarket (sentiment del d√≠a anterior actualizado)\")\n"
      ]
    }
  ]
}