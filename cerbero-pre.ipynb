{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtpdLc0a7fvgqnovzmHcMF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4L3M4R/cerbero/blob/main/cerbero-pre.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYcC5-caMLbD"
      },
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "#             CERBERO PREMARKET\n",
        "#   Descarga noticias y calcula sentiment\n",
        "#   (Actualiza el d√≠a anterior en los archivos *_datos.txt)\n",
        "# ===============================================\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import feedparser\n",
        "import nltk\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from datetime import datetime, timedelta\n",
        "from urllib.parse import quote\n",
        "\n",
        "# ===============================================\n",
        "#             CONFIGURACI√ìN\n",
        "# ===============================================\n",
        "\n",
        "# Lista de activos\n",
        "activos = {}\n",
        "with open(\"activos.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        symbol, source, search_name = line.strip().split(\":\")\n",
        "        activos[symbol.strip()] = {\n",
        "            \"source\": source.strip().lower(),\n",
        "            \"search_name\": search_name.strip()\n",
        "        }\n",
        "\n",
        "# Inicializaci√≥n de analizadores de sentimiento\n",
        "nltk.download('vader_lexicon')\n",
        "vader_analyzer = SentimentIntensityAnalyzer()\n",
        "finbert_tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "finbert_model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "\n",
        "# ===============================================\n",
        "#           FUNCIONES AUXILIARES\n",
        "# ===============================================\n",
        "\n",
        "def registrar_log(message, log_file=\"run_summary_pre.log\"):\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    with open(log_file, \"a\") as log:\n",
        "        log.write(f\"[{timestamp}] {message}\\n\")\n",
        "\n",
        "def descargar_noticias_y_calcular_sentiment(symbol, search_name):\n",
        "    os.makedirs(\"logs\", exist_ok=True)\n",
        "\n",
        "    query = quote(search_name)\n",
        "    feed = feedparser.parse(f\"https://news.google.com/rss/search?q={query}\")\n",
        "    noticias = []\n",
        "    for entry in feed.entries:\n",
        "        noticias.append({\n",
        "            \"timestamp\": entry.published,\n",
        "            \"title\": entry.title,\n",
        "            \"link\": entry.link\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(noticias)\n",
        "    if df.empty:\n",
        "        registrar_log(f\"{symbol} - No se encontraron noticias\")\n",
        "        return\n",
        "\n",
        "    # Calcular sentimiento con VADER (y placeholder para FinBERT)\n",
        "    df[\"vader_sentiment\"] = df[\"title\"].apply(lambda x: vader_analyzer.polarity_scores(x)[\"compound\"])\n",
        "    df[\"finbert_sentiment\"] = 0  # Puedes reemplazar con an√°lisis FinBERT si lo deseas\n",
        "\n",
        "    # Calcular promedios\n",
        "    vader_promedio = df[\"vader_sentiment\"].mean()\n",
        "    finbert_promedio = df[\"finbert_sentiment\"].mean()\n",
        "\n",
        "    # Actualizar el archivo de datos\n",
        "    actualizar_sentimiento(symbol, vader_promedio, finbert_promedio)\n",
        "\n",
        "    # Guardar noticias procesadas\n",
        "    today_str = pd.Timestamp.utcnow().date()\n",
        "    df.to_csv(f\"logs/{symbol}_nuevas_agregadas_{today_str}.csv\", index=False)\n",
        "    registrar_log(f\"{symbol} - Guardadas {len(df)} noticias con sentiment\")\n",
        "\n",
        "def actualizar_sentimiento(symbol, vader_promedio, finbert_promedio):\n",
        "    \"\"\"\n",
        "    Actualiza el archivo *_datos.txt del s√≠mbolo con el sentiment promedio calculado.\n",
        "    Se integra con el flujo del postmarket, respetando formato tab-separado.\n",
        "    En premarket, actualiza la √∫ltima fila (previa).\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import pandas as pd\n",
        "    from datetime import datetime, timedelta\n",
        "\n",
        "    filename = f\"{symbol}_datos.txt\"\n",
        "\n",
        "    # --- Cargar archivo existente ---\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"‚ö†Ô∏è Archivo no encontrado: {filename}. Creando nuevo archivo.\")\n",
        "        # Crear DataFrame m√≠nimo\n",
        "        df = pd.DataFrame([{\n",
        "            \"timestamp\": (datetime.utcnow().date() - timedelta(days=1)).strftime(\"%Y-%m-%d\"),\n",
        "            \"vader\": vader_promedio,\n",
        "            \"finbert\": finbert_promedio\n",
        "        }])\n",
        "        df.to_csv(filename, sep=\"\\t\", index=False)\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(filename, sep=\"\\t\")\n",
        "    print(f\"‚úÖ Archivo cargado correctamente: {filename}\")\n",
        "\n",
        "    # --- Preprocesar timestamps ---\n",
        "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
        "    df[\"timestamp\"] = df[\"timestamp\"].dt.tz_localize(None)\n",
        "    df[\"date_only\"] = df[\"timestamp\"].dt.date\n",
        "\n",
        "    # --- Determinar fecha a actualizar: √∫ltima fila (previa) ---\n",
        "    last_date = df[\"date_only\"].max()\n",
        "    last_idx = df[df[\"date_only\"] == last_date].index\n",
        "\n",
        "    if len(last_idx) == 0:\n",
        "        print(\"‚ö†Ô∏è No se encontr√≥ fila para actualizar, agregando nueva fila.\")\n",
        "        new_row = {\n",
        "            \"timestamp\": (datetime.utcnow().date() - timedelta(days=1)).strftime(\"%Y-%m-%d\"),\n",
        "            \"vader\": vader_promedio,\n",
        "            \"finbert\": finbert_promedio\n",
        "        }\n",
        "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "    else:\n",
        "        # Actualizar valores de la √∫ltima fila\n",
        "        df.loc[last_idx, \"vader\"] = vader_promedio\n",
        "        df.loc[last_idx, \"finbert\"] = finbert_promedio\n",
        "        print(f\"üü¢ Actualizado sentiment para {last_date} en fila {last_idx[0]}\")\n",
        "\n",
        "    # --- Guardar ---\n",
        "    df.drop(columns=[\"date_only\"], inplace=True, errors=\"ignore\")\n",
        "    df.to_csv(filename, sep=\"\\t\", index=False)\n",
        "    print(f\"üíæ Archivo actualizado y guardado: {filename} | Filas totales: {len(df)}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===============================================\n",
        "#           EJECUCI√ìN PRINCIPAL\n",
        "# ===============================================\n",
        "\n",
        "for symbol, info in activos.items():\n",
        "    descargar_noticias_y_calcular_sentiment(symbol, info[\"search_name\"])\n",
        "\n",
        "print(\"‚úÖ Completed premarket (sentiment del d√≠a anterior actualizado)\")\n"
      ]
    }
  ]
}