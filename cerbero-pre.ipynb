{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXNCV7vAPVSNc52hmbz84x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4L3M4R/cerbero/blob/main/cerbero-pre.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYcC5-caMLbD"
      },
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "#             CERBERO PREMARKET\n",
        "#   Descarga noticias y calcula sentiment\n",
        "#   (Actualiza el día anterior en los archivos *_datos.txt)\n",
        "# ===============================================\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import feedparser\n",
        "import nltk\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from datetime import datetime, timedelta\n",
        "from urllib.parse import quote\n",
        "\n",
        "# ===============================================\n",
        "#             CONFIGURACIÓN\n",
        "# ===============================================\n",
        "\n",
        "# Lista de activos\n",
        "activos = {}\n",
        "with open(\"activos.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        symbol, source, search_name = line.strip().split(\":\")\n",
        "        activos[symbol.strip()] = {\n",
        "            \"source\": source.strip().lower(),\n",
        "            \"search_name\": search_name.strip()\n",
        "        }\n",
        "\n",
        "# Inicialización de analizadores de sentimiento\n",
        "nltk.download('vader_lexicon')\n",
        "vader_analyzer = SentimentIntensityAnalyzer()\n",
        "finbert_tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "finbert_model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "\n",
        "# ===============================================\n",
        "#           FUNCIONES AUXILIARES\n",
        "# ===============================================\n",
        "\n",
        "def registrar_log(message, log_file=\"run_summary_pre.log\"):\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    with open(log_file, \"a\") as log:\n",
        "        log.write(f\"[{timestamp}] {message}\\n\")\n",
        "\n",
        "def descargar_noticias_y_calcular_sentiment_df(df, symbol, search_name):\n",
        "    \"\"\"\n",
        "    Descarga noticias, calcula el sentiment y actualiza el DataFrame pasado.\n",
        "    Devuelve el DataFrame actualizado en memoria sin guardar todavía en disco.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import pandas as pd\n",
        "    from urllib.parse import quote\n",
        "    import feedparser\n",
        "\n",
        "    os.makedirs(\"logs\", exist_ok=True)\n",
        "\n",
        "    # ========================\n",
        "    # Descargar noticias\n",
        "    # ========================\n",
        "    query = quote(search_name)\n",
        "    feed = feedparser.parse(f\"https://news.google.com/rss/search?q={query}\")\n",
        "    noticias = []\n",
        "    for entry in feed.entries:\n",
        "        noticias.append({\n",
        "            \"timestamp\": entry.published,\n",
        "            \"title\": entry.title,\n",
        "            \"link\": entry.link\n",
        "        })\n",
        "\n",
        "    noticias_df = pd.DataFrame(noticias)\n",
        "    if noticias_df.empty:\n",
        "        registrar_log(f\"{symbol} - No se encontraron noticias\")\n",
        "    else:\n",
        "        # Calcular sentimiento con VADER (placeholder FinBERT)\n",
        "        noticias_df[\"vader_sentiment\"] = noticias_df[\"title\"].apply(lambda x: vader_analyzer.polarity_scores(x)[\"compound\"])\n",
        "        noticias_df[\"finbert_sentiment\"] = 0\n",
        "\n",
        "        # Promedios\n",
        "        vader_promedio = noticias_df[\"vader_sentiment\"].mean()\n",
        "        finbert_promedio = noticias_df[\"finbert_sentiment\"].mean()\n",
        "\n",
        "        # Guardar noticias procesadas\n",
        "        today_str = pd.Timestamp.utcnow().date()\n",
        "        noticias_df.to_csv(f\"logs/{symbol}_nuevas_agregadas_{today_str}.csv\", index=False)\n",
        "        registrar_log(f\"{symbol} - Guardadas {len(noticias_df)} noticias con sentiment\")\n",
        "\n",
        "        # ========================\n",
        "        # Actualizar DataFrame principal\n",
        "        # ========================\n",
        "        if df.empty:\n",
        "            # Creamos fila mínima con todas las columnas del CSV si no existía\n",
        "            df = pd.DataFrame([{\n",
        "                \"timestamp\": (pd.Timestamp.utcnow().date() - pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\"),\n",
        "                \"vader\": vader_promedio,\n",
        "                \"finbert\": finbert_promedio,\n",
        "                \"sentiment_ratio\": vader_promedio / (finbert_promedio + 1e-9),\n",
        "                \"sentiment_combined\": (vader_promedio + finbert_promedio) / 2\n",
        "            }])\n",
        "        else:\n",
        "            df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
        "            df[\"timestamp\"] = df[\"timestamp\"].dt.tz_localize(None)\n",
        "            df[\"date_only\"] = df[\"timestamp\"].dt.date\n",
        "            last_date = df[\"date_only\"].max()\n",
        "            last_idx = df[df[\"date_only\"] == last_date].index\n",
        "\n",
        "            if len(last_idx) == 0:\n",
        "                # Añadir nueva fila mínima con columnas existentes\n",
        "                new_row = {col: None for col in df.columns}\n",
        "                new_row.update({\n",
        "                    \"timestamp\": (pd.Timestamp.utcnow().date() - pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\"),\n",
        "                    \"vader\": vader_promedio,\n",
        "                    \"finbert\": finbert_promedio,\n",
        "                    \"sentiment_ratio\": vader_promedio / (finbert_promedio + 1e-9),\n",
        "                    \"sentiment_combined\": (vader_promedio + finbert_promedio) / 2\n",
        "                })\n",
        "                df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "            else:\n",
        "                # Actualizar última fila\n",
        "                df.loc[last_idx, \"vader\"] = vader_promedio\n",
        "                df.loc[last_idx, \"finbert\"] = finbert_promedio\n",
        "                df.loc[last_idx, \"sentiment_ratio\"] = vader_promedio / (finbert_promedio + 1e-9)\n",
        "                df.loc[last_idx, \"sentiment_combined\"] = (vader_promedio + finbert_promedio) / 2\n",
        "\n",
        "            df.drop(columns=[\"date_only\"], inplace=True, errors=\"ignore\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def calcular_target_df(df, symbol=None):\n",
        "    \"\"\"\n",
        "    Calcula el target de subida como número y su categoría.\n",
        "    Se leen thresholds y modo desde config.txt.\n",
        "    Mantiene todas las columnas existentes y añade:\n",
        "        - target (numérico)\n",
        "        - target_category (categórico)\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "\n",
        "    # ========================\n",
        "    # Leer thresholds y modo\n",
        "    # ========================\n",
        "    target_config = {}\n",
        "    mode = \"daily\"\n",
        "    with open(\"config.txt\", \"r\") as f:\n",
        "        for line in f:\n",
        "            if \"=\" in line:\n",
        "                key, value = line.strip().split(\"=\")\n",
        "                key = key.strip()\n",
        "                value = value.strip()\n",
        "                if key in [\"high_threshold\", \"medium_threshold\", \"low_threshold\", \"below_threshold\"]:\n",
        "                    target_config[key] = float(value)\n",
        "                elif key == \"mode\":\n",
        "                    mode = value.lower()\n",
        "\n",
        "    # ========================\n",
        "    # Crear columnas si no existen\n",
        "    # ========================\n",
        "    if \"target_category\" not in df.columns:\n",
        "        df[\"target_category\"] = None\n",
        "    if \"target\" not in df.columns:\n",
        "        df[\"target\"] = pd.NA\n",
        "\n",
        "    # ========================\n",
        "    # Función de categorización\n",
        "    # ========================\n",
        "    def categorizar(r):\n",
        "        if pd.isna(r):\n",
        "            return None\n",
        "        elif r >= target_config[\"high_threshold\"]:\n",
        "            return \"Very High\"\n",
        "        elif r >= target_config[\"medium_threshold\"]:\n",
        "            return \"High\"\n",
        "        elif r >= target_config[\"low_threshold\"]:\n",
        "            return \"Medium\"\n",
        "        elif r >= target_config[\"below_threshold\"]:\n",
        "            return \"Low\"\n",
        "        else:\n",
        "            return \"Negative\"\n",
        "\n",
        "    def categorizar_num(r):\n",
        "        if pd.isna(r):\n",
        "            return None\n",
        "        elif r >= target_config[\"high_threshold\"]:\n",
        "            return \"4\"\n",
        "        elif r >= target_config[\"medium_threshold\"]:\n",
        "            return \"3\"\n",
        "        elif r >= target_config[\"low_threshold\"]:\n",
        "            return \"2\"\n",
        "        elif r >= target_config[\"below_threshold\"]:\n",
        "            return \"1\"\n",
        "        else:\n",
        "            return \"0\"\n",
        "    # ========================\n",
        "    # Función de cálculo de target numérico\n",
        "    # ========================\n",
        "    def calcular_target(r):\n",
        "        if pd.isna(r):\n",
        "            return pd.NA\n",
        "        # Simplemente devolvemos el return_pct como target\n",
        "        # Si quieres otra fórmula, se puede ajustar aquí\n",
        "        return r\n",
        "\n",
        "    # ========================\n",
        "    # Procesar solo si existe return_pct\n",
        "    # ========================\n",
        "    if \"return_pct\" not in df.columns:\n",
        "        df[\"return_pct\"] = pd.NA\n",
        "\n",
        "    # Elegir filas según modo\n",
        "    if mode == \"daily\":\n",
        "        idx = df.index[-1:]  # última fila\n",
        "    else:\n",
        "        idx = df.index       # todas las filas\n",
        "\n",
        "    # Aplicar cálculo\n",
        "    df.loc[idx, \"target\"] = df.loc[idx, \"return_pct\"].apply(calcular_target)\n",
        "    df.loc[idx, \"target_category\"] = df.loc[idx, \"return_pct\"].apply(categorizar)\n",
        "    df.loc[idx, \"target_num\"] = df.loc[idx, \"return_pct\"].apply(categorizar_num)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===============================================\n",
        "#           EJECUCIÓN PRINCIPAL\n",
        "# ===============================================\n",
        "\n",
        "\n",
        "for symbol, info in activos.items():\n",
        "    filename = f\"{symbol}_datos.txt\"\n",
        "    df = pd.read_csv(filename, sep=\"\\t\") if os.path.exists(filename) else pd.DataFrame()\n",
        "\n",
        "    # Descargar noticias y actualizar sentimiento en memoria\n",
        "    df = descargar_noticias_y_calcular_sentiment_df(df, symbol, info[\"search_name\"])\n",
        "\n",
        "    # Calcular target usando la función que lee el modo desde activos.txt\n",
        "    df = calcular_target_df(df, symbol)\n",
        "\n",
        "    # Guardar todo el DataFrame una sola vez\n",
        "    df.to_csv(filename, sep=\"\\t\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"✅ Completed premarket (sentiment del día anterior actualizado)\")\n"
      ]
    }
  ]
}