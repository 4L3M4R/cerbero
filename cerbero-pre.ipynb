{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFND6lzbFRZzmXDn1ZRKL3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4L3M4R/cerbero/blob/main/cerbero-pre.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYcC5-caMLbD"
      },
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "#             CERBERO PREMARKET\n",
        "#   Descarga noticias y calcula sentiment\n",
        "#   (Actualiza el día anterior en los archivos *_datos.txt)\n",
        "# ===============================================\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import feedparser\n",
        "import nltk\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from datetime import datetime, timedelta\n",
        "from urllib.parse import quote\n",
        "\n",
        "# ===============================================\n",
        "#             CONFIGURACIÓN\n",
        "# ===============================================\n",
        "\n",
        "# Lista de activos\n",
        "activos = {}\n",
        "with open(\"activos.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        symbol, source, search_name = line.strip().split(\":\")\n",
        "        activos[symbol.strip()] = {\n",
        "            \"source\": source.strip().lower(),\n",
        "            \"search_name\": search_name.strip()\n",
        "        }\n",
        "\n",
        "# Inicialización de analizadores de sentimiento\n",
        "nltk.download('vader_lexicon')\n",
        "vader_analyzer = SentimentIntensityAnalyzer()\n",
        "finbert_tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "finbert_model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "\n",
        "# ===============================================\n",
        "#           FUNCIONES AUXILIARES\n",
        "# ===============================================\n",
        "\n",
        "def registrar_log(message, log_file=\"run_summary_pre.log\"):\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    with open(log_file, \"a\") as log:\n",
        "        log.write(f\"[{timestamp}] {message}\\n\")\n",
        "\n",
        "def descargar_noticias_y_calcular_sentiment_df(df, symbol, search_name):\n",
        "    \"\"\"\n",
        "    Descarga noticias, calcula el sentiment y actualiza el DataFrame pasado.\n",
        "    Devuelve el DataFrame actualizado en memoria sin guardar todavía en disco.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import pandas as pd\n",
        "    from urllib.parse import quote\n",
        "    import feedparser\n",
        "\n",
        "    os.makedirs(\"logs\", exist_ok=True)\n",
        "\n",
        "    # ========================\n",
        "    # Descargar noticias\n",
        "    # ========================\n",
        "    query = quote(search_name)\n",
        "    feed = feedparser.parse(f\"https://news.google.com/rss/search?q={query}\")\n",
        "    noticias = []\n",
        "    for entry in feed.entries:\n",
        "        noticias.append({\n",
        "            \"timestamp\": entry.published,\n",
        "            \"title\": entry.title,\n",
        "            \"link\": entry.link\n",
        "        })\n",
        "\n",
        "    noticias_df = pd.DataFrame(noticias)\n",
        "    if noticias_df.empty:\n",
        "        registrar_log(f\"{symbol} - No se encontraron noticias\")\n",
        "    else:\n",
        "        # Calcular sentimiento con VADER (placeholder FinBERT)\n",
        "        noticias_df[\"vader_sentiment\"] = noticias_df[\"title\"].apply(lambda x: vader_analyzer.polarity_scores(x)[\"compound\"])\n",
        "        noticias_df[\"finbert_sentiment\"] = 0\n",
        "\n",
        "        # Promedios\n",
        "        vader_promedio = noticias_df[\"vader_sentiment\"].mean()\n",
        "        finbert_promedio = noticias_df[\"finbert_sentiment\"].mean()\n",
        "\n",
        "        # Guardar noticias procesadas\n",
        "        today_str = pd.Timestamp.utcnow().date()\n",
        "        noticias_df.to_csv(f\"logs/{symbol}_nuevas_agregadas_{today_str}.csv\", index=False)\n",
        "        registrar_log(f\"{symbol} - Guardadas {len(noticias_df)} noticias con sentiment\")\n",
        "\n",
        "        # ========================\n",
        "        # Actualizar DataFrame principal\n",
        "        # ========================\n",
        "        if df.empty:\n",
        "            # Creamos fila mínima con todas las columnas del CSV si no existía\n",
        "            df = pd.DataFrame([{\n",
        "                \"timestamp\": (pd.Timestamp.utcnow().date() - pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\"),\n",
        "                \"vader\": vader_promedio,\n",
        "                \"finbert\": finbert_promedio,\n",
        "                \"sentiment_ratio\": vader_promedio / (finbert_promedio + 1e-9),\n",
        "                \"sentiment_combined\": (vader_promedio + finbert_promedio) / 2\n",
        "            }])\n",
        "        else:\n",
        "            df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
        "            df[\"timestamp\"] = df[\"timestamp\"].dt.tz_localize(None)\n",
        "            df[\"date_only\"] = df[\"timestamp\"].dt.date\n",
        "            last_date = df[\"date_only\"].max()\n",
        "            last_idx = df[df[\"date_only\"] == last_date].index\n",
        "\n",
        "            if len(last_idx) == 0:\n",
        "                # Añadir nueva fila mínima con columnas existentes\n",
        "                new_row = {col: None for col in df.columns}\n",
        "                new_row.update({\n",
        "                    \"timestamp\": (pd.Timestamp.utcnow().date() - pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\"),\n",
        "                    \"vader\": vader_promedio,\n",
        "                    \"finbert\": finbert_promedio,\n",
        "                    \"sentiment_ratio\": vader_promedio / (finbert_promedio + 1e-9),\n",
        "                    \"sentiment_combined\": (vader_promedio + finbert_promedio) / 2\n",
        "                })\n",
        "                df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "            else:\n",
        "                # Actualizar última fila\n",
        "                df.loc[last_idx, \"vader\"] = vader_promedio\n",
        "                df.loc[last_idx, \"finbert\"] = finbert_promedio\n",
        "                df.loc[last_idx, \"sentiment_ratio\"] = vader_promedio / (finbert_promedio + 1e-9)\n",
        "                df.loc[last_idx, \"sentiment_combined\"] = (vader_promedio + finbert_promedio) / 2\n",
        "\n",
        "            df.drop(columns=[\"date_only\"], inplace=True, errors=\"ignore\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# ===============================================\n",
        "#           EJECUCIÓN PRINCIPAL\n",
        "# ===============================================\n",
        "\n",
        "\n",
        "for symbol, info in activos.items():\n",
        "    filename = f\"{symbol}_datos.txt\"\n",
        "    df = pd.read_csv(filename, sep=\"\\t\") if os.path.exists(filename) else pd.DataFrame()\n",
        "\n",
        "    # Descargar noticias y actualizar sentimiento en memoria\n",
        "    df = descargar_noticias_y_calcular_sentiment_df(df, symbol, info[\"search_name\"])\n",
        "\n",
        "    # Calcular target usando la función que lee el modo desde activos.txt\n",
        "    df = calcular_target_df(df, symbol)\n",
        "\n",
        "    # Guardar todo el DataFrame una sola vez\n",
        "    df.to_csv(filename, sep=\"\\t\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"✅ Completed premarket (sentiment del día anterior actualizado)\")\n"
      ]
    }
  ]
}