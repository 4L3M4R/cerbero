{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6cuL/Z2rrbsa20m+4LLTV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4L3M4R/cerbero/blob/main/cerbero-pre.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYcC5-caMLbD"
      },
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "#             CERBERO PREMARKET\n",
        "#   Descarga noticias y calcula sentiment\n",
        "#   (Actualiza el d√≠a anterior en los archivos *_datos.txt)\n",
        "# ===============================================\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import feedparser\n",
        "import nltk\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from datetime import datetime, timedelta\n",
        "from urllib.parse import quote\n",
        "\n",
        "# ===============================================\n",
        "#             CONFIGURACI√ìN\n",
        "# ===============================================\n",
        "\n",
        "# Lista de activos\n",
        "activos = {}\n",
        "with open(\"activos.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        symbol, source, search_name = line.strip().split(\":\")\n",
        "        activos[symbol.strip()] = {\n",
        "            \"source\": source.strip().lower(),\n",
        "            \"search_name\": search_name.strip()\n",
        "        }\n",
        "\n",
        "# Inicializaci√≥n de analizadores de sentimiento\n",
        "nltk.download('vader_lexicon')\n",
        "vader_analyzer = SentimentIntensityAnalyzer()\n",
        "finbert_tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "finbert_model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "\n",
        "# ===============================================\n",
        "#           FUNCIONES AUXILIARES\n",
        "# ===============================================\n",
        "\n",
        "def registrar_log(message, log_file=\"run_summary_pre.log\"):\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    with open(log_file, \"a\") as log:\n",
        "        log.write(f\"[{timestamp}] {message}\\n\")\n",
        "\n",
        "def descargar_noticias_y_calcular_sentiment(symbol, search_name):\n",
        "    os.makedirs(\"logs\", exist_ok=True)\n",
        "\n",
        "    query = quote(search_name)\n",
        "    feed = feedparser.parse(f\"https://news.google.com/rss/search?q={query}\")\n",
        "    noticias = []\n",
        "    for entry in feed.entries:\n",
        "        noticias.append({\n",
        "            \"timestamp\": entry.published,\n",
        "            \"title\": entry.title,\n",
        "            \"link\": entry.link\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(noticias)\n",
        "    if df.empty:\n",
        "        registrar_log(f\"{symbol} - No se encontraron noticias\")\n",
        "        return\n",
        "\n",
        "    # Calcular sentimiento con VADER (y placeholder para FinBERT)\n",
        "    df[\"vader_sentiment\"] = df[\"title\"].apply(lambda x: vader_analyzer.polarity_scores(x)[\"compound\"])\n",
        "    df[\"finbert_sentiment\"] = 0  # Puedes reemplazar con an√°lisis FinBERT si lo deseas\n",
        "\n",
        "    # Calcular promedios\n",
        "    vader_promedio = df[\"vader_sentiment\"].mean()\n",
        "    finbert_promedio = df[\"finbert_sentiment\"].mean()\n",
        "\n",
        "    # Actualizar el archivo de datos\n",
        "    actualizar_sentimiento(symbol, vader_promedio, finbert_promedio)\n",
        "\n",
        "    # Guardar noticias procesadas\n",
        "    today_str = pd.Timestamp.utcnow().date()\n",
        "    df.to_csv(f\"logs/{symbol}_nuevas_agregadas_{today_str}.csv\", index=False)\n",
        "    registrar_log(f\"{symbol} - Guardadas {len(df)} noticias con sentiment\")\n",
        "\n",
        "def actualizar_sentimiento(symbol, vader_promedio, finbert_promedio):\n",
        "    \"\"\"Actualiza la l√≠nea del D√çA ANTERIOR en el archivo datos_{symbol}.txt con el sentimiento promedio.\"\"\"\n",
        "    import pandas as pd\n",
        "    import os\n",
        "    file_path = f\"{symbol}_datos.txt\"\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"‚ö†Ô∏è Archivo no encontrado: {file_path}\")\n",
        "        registrar_log(f\"{symbol} - Archivo de datos no encontrado: {file_path}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except Exception as e:\n",
        "        registrar_log(f\"{symbol} - Error leyendo archivo {file_path}: {e}\")\n",
        "        print(f\"‚ùå Error leyendo {file_path}: {e}\")\n",
        "        return\n",
        "\n",
        "    print(f\"‚úÖ Archivo cargado correctamente: {file_path}\")\n",
        "\n",
        "    # --- Identificar columna de fecha ---\n",
        "    date_col = None\n",
        "    for col in df.columns:\n",
        "        if col.lower() in [\"timestamp\", \"date\", \"fecha\", \"day\"]:\n",
        "            date_col = col\n",
        "            break\n",
        "\n",
        "    if date_col is None:\n",
        "        registrar_log(f\"{symbol} - No se encontr√≥ columna de fecha en {file_path}\")\n",
        "        print(\"‚ö†Ô∏è No se encontr√≥ columna de fecha, no se actualiza.\")\n",
        "        return\n",
        "\n",
        "    df[\"timestamp\"] = pd.to_datetime(df[date_col], errors=\"coerce\").dt.date\n",
        "\n",
        "    # --- Buscar la l√≠nea del d√≠a ANTERIOR ---\n",
        "    ayer = (datetime.now() - timedelta(days=1)).date()\n",
        "    mask = df[\"timestamp\"] == ayer\n",
        "\n",
        "    if mask.any():\n",
        "        print(f\"üü¢ Actualizando l√≠nea existente para {ayer} en {symbol}\")\n",
        "        df.loc[mask, \"vader_sentiment\"] = vader_promedio\n",
        "        df.loc[mask, \"finbert_sentiment\"] = finbert_promedio\n",
        "        registrar_log(f\"{symbol} - Sentimiento actualizado para {ayer}: Vader={vader_promedio:.3f}, FinBERT={finbert_promedio:.3f}\")\n",
        "    else:\n",
        "        print(f\"üü° No existe l√≠nea para {ayer}, agregando nueva fila.\")\n",
        "        nueva_fila = pd.DataFrame({\n",
        "            \"timestamp\": [ayer],\n",
        "            \"vader_sentiment\": [vader_promedio],\n",
        "            \"finbert_sentiment\": [finbert_promedio],\n",
        "        })\n",
        "        df = pd.concat([df, nueva_fila], ignore_index=True)\n",
        "        registrar_log(f\"{symbol} - Nueva fila agregada para {ayer}\")\n",
        "\n",
        "    # --- Guardar el archivo actualizado ---\n",
        "    df.to_csv(file_path, index=False)\n",
        "    print(f\"üíæ Archivo actualizado y guardado: {file_path}\")\n",
        "\n",
        "# ===============================================\n",
        "#           EJECUCI√ìN PRINCIPAL\n",
        "# ===============================================\n",
        "\n",
        "for symbol, info in activos.items():\n",
        "    descargar_noticias_y_calcular_sentiment(symbol, info[\"search_name\"])\n",
        "\n",
        "print(\"‚úÖ Completed premarket (sentiment del d√≠a anterior actualizado)\")\n"
      ]
    }
  ]
}