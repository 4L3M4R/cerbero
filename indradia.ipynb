{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwCb5GduTCzkklI90ry+PP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4L3M4R/intraday/blob/main/indradia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc2HruDymyB5",
        "outputId": "b3301814-ae0d-4c0a-d6a9-10710c4b6dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas_ta in /usr/local/lib/python3.12/dist-packages (0.4.71b0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.12/dist-packages (3.3.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (0.61.2)\n",
            "Requirement already satisfied: numpy>=2.2.6 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (2.2.6)\n",
            "Requirement already satisfied: pandas>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (2.3.2)\n",
            "Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (4.67.1)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba==0.61.2->pandas_ta) (0.44.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.4.0)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Collecting sgmllib3k (from feedparser)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.8.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.3.2->pandas_ta) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.3.2->pandas_ta) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.3.2->pandas_ta) (1.17.0)\n",
            "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=7619befd2e06bcf545da406fac5ff885e23aca82a467d12ab5824785d925913a\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser\n",
            "Successfully installed feedparser-6.0.12 sgmllib3k-1.0.0\n"
          ]
        }
      ],
      "source": [
        "#!pip install pandas_ta yfinance vaderSentiment transformers torch feedparser"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "#import pandas_ta as ta\n",
        "from ta.momentum import RSIIndicator, ROCIndicator\n",
        "from ta.trend import MACD\n",
        "from ta.volatility import AverageTrueRange, BollingerBands\n",
        "# import pandas_ta as pta  # Uncomment if you want to use pandas_ta in the future\n",
        "\n",
        "\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "import os\n"
      ],
      "metadata": {
        "id": "U10xhlO2nAOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Leer lista de activos y fuentes ---\n",
        "with open(\"activos.txt\", \"r\") as f:\n",
        "    activos = {}\n",
        "    for line in f:\n",
        "        if \":\" in line:\n",
        "            symbol, source = line.strip().split(\":\")\n",
        "            activos[symbol.strip()] = source.strip().lower()\n",
        "\n",
        "# --- Leer configuración ---\n",
        "config = {}\n",
        "with open(\"config.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        if \":\" in line:\n",
        "            key, value = line.strip().split(\":\")\n",
        "            config[key.strip()] = value.strip()\n",
        "\n",
        "granularity = config.get(\"frecuencia\", \"1h\")\n",
        "limit = int(config.get(\"limit\", \"100\"))\n",
        "period = config.get(\"period\", \"5d\")\n"
      ],
      "metadata": {
        "id": "5TUTW3m1nDMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Descargar desde Bitget ---\n",
        "def descargar_datos_bitget(symbol, granularity, limit):\n",
        "    url = \"https://api.bitget.com/api/v2/mix/market/history-candles\"\n",
        "    params = {\n",
        "        \"symbol\": symbol,\n",
        "        \"productType\": \"USDT-FUTURES\",\n",
        "        \"granularity\": granularity,\n",
        "        \"limit\": limit\n",
        "    }\n",
        "    print(f\"Descargando desde Bitget: {symbol}...\")\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json().get(\"data\", [])\n",
        "        if not data:\n",
        "            print(f\"No hay datos para {symbol}\")\n",
        "            return None\n",
        "        df = pd.DataFrame(data, columns=[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"quoteVolume\"])\n",
        "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"].astype(int), unit='ms', utc=True)\n",
        "        df[\"symbol\"] = symbol\n",
        "        return df.sort_values(\"timestamp\")\n",
        "    else:\n",
        "        print(f\"Error Bitget {symbol}: {response.text}\")\n",
        "        return None\n",
        "\n",
        "# --- Descargar desde Yahoo Finance ---\n",
        "def descargar_datos_yf(symbol, interval, period, limit):\n",
        "    print(f\"Descargando desde Yahoo Finance: {symbol}...\")\n",
        "    try:\n",
        "        data = yf.download(tickers=symbol, interval=interval, period=period)\n",
        "        if data.empty:\n",
        "            print(f\"No se encontraron datos para {symbol}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "\n",
        "        # Si las columnas tienen múltiples niveles (multiindex), aplánalas\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            data.columns = [col[0].lower() for col in data.columns]\n",
        "\n",
        "        else:\n",
        "            data.columns = [col.lower() for col in data.columns]\n",
        "\n",
        "        # Reset index para convertir fecha a columna\n",
        "        data = data.reset_index()\n",
        "\n",
        "        # Renombrar columnas importantes\n",
        "        rename_map = {\n",
        "            'open': 'open',\n",
        "            'high': 'high',\n",
        "            'low': 'low',\n",
        "            'close': 'close',\n",
        "            'volume': 'volume',\n",
        "            'Date': 'timestamp'\n",
        "        }\n",
        "\n",
        "        data.rename(columns=rename_map, inplace=True)\n",
        "\n",
        "        # Añadir columna symbol\n",
        "        data[\"symbol\"] = symbol\n",
        "\n",
        "\n",
        "        return data.head(limit)\n",
        "    except Exception as e:\n",
        "        print(f\"Error Yahoo {symbol}: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "8g__MkA5nOYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Cálculo de indicadores ---\n",
        "def calcular_features(df):\n",
        "    for col in ['open', 'high', 'low', 'close', 'volume']:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # Price/volume features\n",
        "    df['gap_apertura_pct'] = (df['open'] - df['close'].shift(1)) / df['close'].shift(1) * 100\n",
        "    df['volatilidad_diaria'] = (df['high'] - df['low']) / df['low'] * 100\n",
        "    df['vol_5d'] = df['volatilidad_diaria'].rolling(5).std()\n",
        "    df['vol_10d'] = df['volatilidad_diaria'].rolling(10).std()\n",
        "    df['vol_rel_5d'] = df['volume'] / df['volume'].rolling(5).mean()\n",
        "    df['return_pct'] = (df['close'] - df['close'].shift(1)) / df['close'].shift(1) * 100\n",
        "    df['close_open_pct'] = (df['close'] - df['open']) / df['open'] * 100\n",
        "    df['range_pct'] = (df['high'] - df['low']) / df['low'] * 100\n",
        "    df['volume_change_pct'] = (df['volume'] - df['volume'].shift(1)) / df['volume'].shift(1) * 100\n",
        "\n",
        "    # TA indicators using `ta` library\n",
        "    df['rsi_14'] = RSIIndicator(close=df['close'], window=14).rsi()\n",
        "    # df['rsi_14'] = pta.rsi(df['close'], length=14)  # pandas_ta version\n",
        "\n",
        "    macd = MACD(close=df['close'], window_slow=26, window_fast=12, window_sign=9)\n",
        "    df['macd'] = macd.macd()\n",
        "    df['macd_signal'] = macd.macd_signal()\n",
        "    df['macd_diff'] = macd.macd_diff()\n",
        "    # macd = pta.macd(df['close'])\n",
        "    # df['macd'] = macd['MACD_12_26_9']\n",
        "    # df['macd_signal'] = macd['MACDs_12_26_9']\n",
        "    # df['macd_diff'] = df['macd'] - df['macd_signal']\n",
        "\n",
        "    df['atr_14'] = AverageTrueRange(high=df['high'], low=df['low'], close=df['close'], window=14).average_true_range()\n",
        "    # df['atr_14'] = pta.atr(df['high'], df['low'], df['close'], length=14)\n",
        "\n",
        "    df['momentum_12'] = ROCIndicator(close=df['close'], window=12).roc()\n",
        "    # df['momentum_12'] = pta.mom(df['close'], length=12)\n",
        "\n",
        "    bb = BollingerBands(close=df['close'], window=20, window_dev=2)\n",
        "    df['bb_upper'] = bb.bollinger_hband()\n",
        "    df['bb_lower'] = bb.bollinger_lband()\n",
        "    df['bb_pctb']  = bb.bollinger_pband()\n",
        "    # try:\n",
        "    #     bb = pta.bbands(df['close'], length=20, std=2)\n",
        "    #     df['bb_upper'] = bb['BBU_20_2.0_2.0']\n",
        "    #     df['bb_lower'] = bb['BBL_20_2.0_2.0']\n",
        "    #     df['bb_pctb']  = bb['BBP_20_2.0_2.0']\n",
        "    # except:\n",
        "    #     df['bb_upper'] = df['bb_lower'] = df['bb_pctb'] = float('nan')\n",
        "\n",
        "    df.fillna(0, inplace=True)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "9LuPAE-pnS8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Guardar ---\n",
        "def save_df(df, symbol):\n",
        "    filename = f\"{symbol}_datos.txt\"\n",
        "    df.to_csv(filename, sep=\"\\t\", index=False)\n",
        "    print(f\"Guardado en {filename}\")\n"
      ],
      "metadata": {
        "id": "SyTJnARJnacu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import nltk\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import feedparser\n",
        "from datetime import datetime\n",
        "\n",
        "# --- Inicializar modelos ---\n",
        "nltk.download('vader_lexicon')\n",
        "vader_analyzer = SentimentIntensityAnalyzer()\n",
        "finbert_tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "finbert_model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "\n",
        "def calcular_sentiment_vader(text):\n",
        "    if not text:\n",
        "        return 0.0\n",
        "    score = vader_analyzer.polarity_scores(text)\n",
        "    return score['compound']\n",
        "\n",
        "def calcular_sentiment_finbert(text):\n",
        "    if not text:\n",
        "        return 0.0\n",
        "    inputs = finbert_tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        outputs = finbert_model(**inputs)\n",
        "    scores = torch.nn.functional.softmax(outputs.logits, dim=-1).numpy()[0]\n",
        "    sentiment_score = scores[0] - scores[2]  # Pos - Neg\n",
        "    return float(sentiment_score)\n",
        "\n",
        "\n",
        "# --- Noticias para acciones desde Yahoo Finance ---\n",
        "def get_news_dataframe(ticker, max_news=50):\n",
        "    stock = yf.Ticker(ticker)\n",
        "    try:\n",
        "        news_items = stock.news[:max_news]\n",
        "    except Exception:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    data = []\n",
        "    for item in news_items:\n",
        "        try:\n",
        "            content = item.get('content', {})\n",
        "            title = content.get('title', '').strip()\n",
        "            description = content.get('description', '').strip()\n",
        "            summary = content.get('summary', '').strip()\n",
        "            pubDate = content.get('pubDate')\n",
        "            if title and pubDate:\n",
        "                dt = pd.to_datetime(pubDate, utc=True)\n",
        "                data.append({\n",
        "                    \"title\": title,\n",
        "                    \"description\": description or summary,\n",
        "                    \"datetime\": dt,\n",
        "                    \"date\": dt.date()\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error al procesar noticia: {e}\")\n",
        "            continue\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# --- Noticias para criptos desde CoinTelegraph RSS ---\n",
        "def get_crypto_news_cointelegraph(symbol, max_news=50):\n",
        "    symbol_map = {\n",
        "        \"BTCUSDT\": \"bitcoin\",\n",
        "        \"ETHUSDT\": \"ethereum\",\n",
        "    }\n",
        "    tag = symbol_map.get(symbol.upper())\n",
        "    if not tag:\n",
        "        print(f\"⚠️ No se encontró tag para {symbol}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    url = f\"https://cointelegraph.com/rss/tag/{tag}\"\n",
        "    feed = feedparser.parse(url)\n",
        "    news_list = []\n",
        "    for entry in feed.entries[:max_news]:\n",
        "        title = entry.get(\"title\", \"\")\n",
        "        description = entry.get(\"summary\", \"\")\n",
        "        published = entry.get(\"published\", \"\")\n",
        "        try:\n",
        "            dt = pd.to_datetime(published, utc=True)\n",
        "        except:\n",
        "            continue\n",
        "        news_list.append({\n",
        "            \"title\": title,\n",
        "            \"description\": description,\n",
        "            \"datetime\": dt,\n",
        "            \"date\": dt.date()\n",
        "        })\n",
        "    return pd.DataFrame(news_list)\n",
        "\n",
        "def agregar_sentiment_diario(df, symbol, source):\n",
        "    if source == \"yfinance\":\n",
        "        news_df = get_news_dataframe(symbol, max_news=100)\n",
        "    elif source == \"bitget\":\n",
        "        news_df = get_crypto_news_cointelegraph(symbol, max_news=100)\n",
        "    else:\n",
        "        news_df = pd.DataFrame()\n",
        "\n",
        "    if news_df.empty:\n",
        "        df[\"vader\"] = 0.0\n",
        "        df[\"finbert\"] = 0.0\n",
        "        df[\"sentiment_ratio\"] = 0.0\n",
        "        df[\"sentiment_combined\"] = 0.0\n",
        "        return df\n",
        "\n",
        "    # Calcular sentimientos\n",
        "    news_df[\"text\"] = news_df[\"title\"] + \". \" + news_df[\"description\"]\n",
        "    news_df[\"vader\"] = news_df[\"text\"].apply(calcular_sentiment_vader)\n",
        "    news_df[\"finbert\"] = news_df[\"text\"].apply(calcular_sentiment_finbert)\n",
        "\n",
        "    # Procesar fechas\n",
        "    news_df[\"date\"] = pd.to_datetime(news_df[\"date\"], errors=\"coerce\", utc=True)\n",
        "    news_df.dropna(subset=[\"date\"], inplace=True)\n",
        "    news_df[\"date_only\"] = news_df[\"date\"].dt.date\n",
        "\n",
        "    # Asegurar timestamp en df\n",
        "    if \"timestamp\" not in df.columns and \"datetime\" in df.columns:\n",
        "        df.rename(columns={\"datetime\": \"timestamp\"}, inplace=True)\n",
        "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True, errors=\"coerce\")\n",
        "    df[\"date_only\"] = df[\"timestamp\"].dt.date\n",
        "\n",
        "    # Agrupar sentimiento por día\n",
        "    daily_sentiment = news_df.groupby(\"date_only\")[[\"vader\", \"finbert\"]].mean().reset_index()\n",
        "\n",
        "    # Hacer merge con df\n",
        "    df = df.merge(daily_sentiment, on=\"date_only\", how=\"left\")\n",
        "    df[[\"vader\", \"finbert\"]] = df[[\"vader\", \"finbert\"]].fillna(0.0)\n",
        "\n",
        "    # Calcular ratio y score combinado\n",
        "    epsilon = 1e-6\n",
        "    df[\"sentiment_ratio\"] = df[\"finbert\"] / (abs(df[\"vader\"]) + epsilon)\n",
        "    df[\"sentiment_combined\"] = 0.7 * df[\"finbert\"] + 0.3 * df[\"vader\"]\n",
        "\n",
        "    # Limpiar\n",
        "    df.drop(columns=[\"date_only\"], inplace=True)\n",
        "\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0MeyVCEMqIn",
        "outputId": "6132bc5d-8470-4e97-9ff8-88b42ba6cb5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Delta Managament\n",
        "# --- Función para cargar df existente ---\n",
        "def cargar_df_existente(symbol):\n",
        "    filename = f\"{symbol}_datos.txt\"\n",
        "    if os.path.exists(filename):\n",
        "        df = pd.read_csv(filename, sep=\"\\t\")\n",
        "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True, errors=\"coerce\")\n",
        "        existing_dates = set(df[\"timestamp\"].dt.date)\n",
        "    else:\n",
        "        df = pd.DataFrame()\n",
        "        existing_dates = set()\n",
        "    return df, existing_dates\n",
        "\n",
        "# --- Función para descargar datos según fuente ---\n",
        "def descargar_datos(symbol, source, granularity, period, limit):\n",
        "    if source == \"bitget\":\n",
        "        return descargar_datos_bitget(symbol, granularity, limit)\n",
        "    elif source == \"yfinance\":\n",
        "        return descargar_datos_yf(symbol, granularity, period, limit)\n",
        "    else:\n",
        "        print(f\"Fuente no soportada: {source}\")\n",
        "        return None\n",
        "\n",
        "# --- Función para filtrar solo nuevas fechas ---\n",
        "def filtrar_nuevas_fechas(df_new, existing_dates):\n",
        "    df_new[\"timestamp\"] = pd.to_datetime(df_new[\"timestamp\"], utc=True)\n",
        "    df_new[\"date_only\"] = df_new[\"timestamp\"].dt.date\n",
        "    df_to_add = df_new[~df_new[\"date_only\"].isin(existing_dates)].copy()\n",
        "    df_to_add.drop(columns=[\"date_only\"], inplace=True)\n",
        "    return df_to_add\n",
        "\n",
        "# --- Función principal para procesar un activo ---\n",
        "def procesar_activo(symbol, source, granularity, period, limit):\n",
        "    df_existing, existing_dates = cargar_df_existente(symbol)\n",
        "    df_new = descargar_datos(symbol, source, granularity, period, limit)\n",
        "    if df_new is None or df_new.empty:\n",
        "        print(f\"No se descargaron datos para {symbol}\")\n",
        "        return\n",
        "    df_to_add = filtrar_nuevas_fechas(df_new, existing_dates)\n",
        "    if df_to_add.empty:\n",
        "        print(f\"No hay nuevas fechas para {symbol}\")\n",
        "        return\n",
        "    df_to_add = calcular_features(df_to_add)\n",
        "    df_to_add = agregar_sentiment_diario(df_to_add, symbol, source)\n",
        "    df_final = pd.concat([df_existing, df_to_add], ignore_index=True) if not df_existing.empty else df_to_add\n",
        "    save_df(df_final, symbol)\n",
        "\n"
      ],
      "metadata": {
        "id": "oPGtAz3tnehr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Loop principal ---\n",
        "for symbol, source in activos.items():\n",
        "    procesar_activo(symbol, source, granularity, period, limit)"
      ],
      "metadata": {
        "id": "WnnaquAW9KxM",
        "outputId": "671dfcec-eafc-4f39-a275-36130c07b304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargando desde Bitget: BTCUSDT...\n",
            "No hay nuevas fechas para BTCUSDT\n",
            "Descargando desde Bitget: ETHUSDT...\n",
            "No hay nuevas fechas para ETHUSDT\n",
            "Descargando desde Yahoo Finance: AAPL...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2106467123.py:29: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(tickers=symbol, interval=interval, period=period)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-2106467123.py:29: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(tickers=symbol, interval=interval, period=period)\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No hay nuevas fechas para AAPL\n",
            "Descargando desde Yahoo Finance: MSFT...\n",
            "No hay nuevas fechas para MSFT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}